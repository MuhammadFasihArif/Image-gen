{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9BKtFcsUWEorNmAUxqfhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadFasihArif/Image-gen/blob/main/Image_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWKUzo9iV7MZ"
      },
      "outputs": [],
      "source": [
        "git clone https://github.com/huggingface/diffusers.git\n",
        "cd diffusers/examples/text_to_image\n",
        "pip install -r requirements.txt accelerate\n",
        "huggingface-cli login\n",
        "\n",
        "export MODEL=\"CompVis/stable-diffusion-v1-4\"\n",
        "export TRAIN_DIR=\"/path/to/your/dataset\"\n",
        "\n",
        "accelerate launch train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL \\\n",
        "  --train_data_dir=$TRAIN_DIR \\\n",
        "  --use_ema \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --max_train_steps=5000 \\\n",
        "  --learning_rate=1e-5 \\\n",
        "  --output_dir=\"sd-finetuned\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_lora.py â€” adapted from harrywang/finetune-sd\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import LoraConfig, LoraLayer\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "class ImageTextDataset(Dataset):\n",
        "    def __init__(self, root, captions_file, transform=None):\n",
        "        self.root, self.transform = root, transform\n",
        "        self.items = [line.strip().split('\\t') for line in open(captions_file)]\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        img_path, caption = self.items[i]\n",
        "        img = Image.open(f\"{self.root}/{img_path}\").convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, caption\n",
        "\n",
        "def main():\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "    config = LoraConfig(r=4, lora_alpha=16, target_modules=[\"unet.up_blocks\", \"unet.down_blocks\"])\n",
        "    pipe.unet.enable_lora(config)\n",
        "\n",
        "    transform = T.Compose([T.Resize(512), T.CenterCrop(512), T.RandomHorizontalFlip(), T.ToTensor()])\n",
        "    ds = ImageTextDataset(\"data/images\", \"data/captions.tsv\", transform)\n",
        "    loader = DataLoader(ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    opt = torch.optim.AdamW(pipe.unet.parameters(), lr=1e-4)\n",
        "    steps = 1000\n",
        "    pipe.unet.train()\n",
        "    for epoch in range(1):\n",
        "        for i, (img, txt) in enumerate(loader):\n",
        "            if i >= steps: break\n",
        "            loss = pipe.train_step(img.to(\"cuda\"), txt)\n",
        "            loss.backward()\n",
        "            opt.step(); opt.zero_grad()\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Step {i}, loss {loss.item():.4f}\")\n",
        "                pipe.save_pretrained(\"lora_output\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "bi5NEP5KWKTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}